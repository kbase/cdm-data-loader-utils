{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8028e12e-c419-4c74-9a77-628d505d4aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/09 23:27:15 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace modelseed_biochemistry is ready to use.\n",
      "{'compound_id': 'cpd00001', 'smiles': 'O', 'inchikey': 'XLYOFNOQVPJJNP-UHFFFAOYSA-N', 'inchi': 'InChI=1S/H2O/h1H2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/09 23:27:17 WARN TaskSetManager: Stage 0 contains a task of very large size (5430 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/01/09 23:27:21 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from io import TextIOWrapper\n",
    "\n",
    "msd_db=\"modelseed_biochemistry\"\n",
    "spark = get_spark_session()\n",
    "create_namespace_if_not_exists(spark, msd_db)\n",
    "\n",
    "header = True\n",
    "structures_url = \"https://raw.githubusercontent.com/ModelSEED/ModelSEEDDatabase/refs/heads/dev/Biochemistry/Structures/Unique_ModelSEED_Structures.txt\"\n",
    "structures_dict = dict()\n",
    "with urlopen(structures_url) as response:\n",
    "\tlines = TextIOWrapper(response)\n",
    "\tfor line in lines:\n",
    "\t\tif(header is True):\n",
    "\t\t\theader = False\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\tline=line.strip('\\r\\n')\n",
    "\t\ttmp_lst = line.split('\\t')\n",
    "\t\t(cpd,struct_type,struct)=(tmp_lst[0],tmp_lst[1],tmp_lst[-1])\n",
    "\n",
    "\t\t# fixing typo\n",
    "\t\tif(struct_type == 'SMILE'):\n",
    "\t\t\tstruct_type+='S'\n",
    "\n",
    "\t\tif(cpd not in structures_dict):\n",
    "\t\t\tstructures_dict[cpd]={'compound_id':cpd}\n",
    "\t\tstructures_dict[cpd][struct_type.lower()]=struct\n",
    "\n",
    "print(structures_dict['cpd00001'])\n",
    "\n",
    "structures = list()\n",
    "for cpd in structures_dict:\n",
    "\n",
    "    # update identifier\n",
    "    structures_dict[cpd]['compound_id'] = 'seed.compound:'+structures_dict[cpd]['compound_id']\n",
    "    \n",
    "    structures.append(structures_dict[cpd])\n",
    "\n",
    "rdd = spark.sparkContext.parallelize(structures)\n",
    "structs_df = spark.read.json(rdd)\n",
    "\n",
    "spark.sql(\"USE modelseed_biochemistry\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS molecular_structure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4e1bf7c-7769-4e3d-b6ca-d0b09e039862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished updating dtypes\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import (\n",
    "\tStringType, LongType, DoubleType, BooleanType\n",
    ")\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "for field, dtype in structs_df.dtypes:\n",
    "        \n",
    "    if(dtype == 'string'):\n",
    "        structs_df = structs_df.withColumn(field, col(field).cast(StringType()))\n",
    "    elif(dtype == 'double'):\n",
    "        structs_df = structs_df.withColumn(field, col(field).cast(DoubleType()))\n",
    "    elif(dtype == 'bigint' and field == 'is_transport'):\n",
    "        structs_df = structs_df.withColumn(field, col(field).cast(BooleanType()))\n",
    "    elif(dtype == 'bigint'):\n",
    "        structs_df = structs_df.withColumn(field, col(field).cast(LongType()))\n",
    "    else:\n",
    "        print(\"Unsupported field?\",field,dtype)\n",
    "\n",
    "print(\"Finished updating dtypes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76a2be18-c91c-4fc2-b3c7-6fc5ab219431",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/09 23:28:09 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "25/01/09 23:29:10 WARN TaskSetManager: Stage 8 contains a task of very large size (5430 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/01/09 23:30:01 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider delta. Persisting data source table `spark_catalog`.`modelseed_biochemistry`.`molecular_structure` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.\n",
      "25/01/09 23:30:01 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n",
      "25/01/09 23:30:01 WARN HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist\n",
      "25/01/09 23:30:01 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "25/01/09 23:30:01 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "chgrp: changing ownership of 'file:///cdm_shared_workspace/hive_metastore/modelseed_biochemistry.db/molecular_structure-__PLACEHOLDER__': chown: changing group of '/cdm_shared_workspace/hive_metastore/modelseed_biochemistry.db/molecular_structure-__PLACEHOLDER__': Operation not permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark table modelseed_biochemistry.molecular_structure created.\n"
     ]
    }
   ],
   "source": [
    "spark_table = f\"{msd_db}.molecular_structure\"\n",
    "delta_file = f\"msd_delta/molecular_structure.delta\"\n",
    "structs_df.write.mode(\"overwrite\") \\\n",
    "        .option(\"overwriteSchema\", \"true\") \\\n",
    "    \t.option(\"compression\", \"snappy\") \\\n",
    "    \t.option(\"path\", f\"s3a://cdm-lake/{delta_file}\") \\\n",
    "    \t.format(\"delta\") \\\n",
    "    \t.saveAsTable(spark_table)\n",
    "print(f\"Spark table {spark_table} created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a8645f-a8a0-4716-b1cc-cb616e3343f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
